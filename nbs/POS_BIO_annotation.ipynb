{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for tokenising with space as token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text\n",
    "\n",
    "def tokenize(raw):\n",
    "    doc = nlp(raw)\n",
    "    token_texts = []\n",
    "    for token in doc:\n",
    "        token_texts.append(token.text)\n",
    "        if token.whitespace_:  # filter out empty strings\n",
    "            token_texts.append(token.whitespace_)\n",
    "    return token_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for obtaining pos tags of token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(raw):\n",
    "    doc = nlp(raw)\n",
    "    \n",
    "    pos_dict = {}\n",
    "    \n",
    "    for token in doc:\n",
    "        pos_dict[str(token)] = str(token.pos_)\n",
    "        \n",
    "    return pos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrative example on English Legal Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_json('~/github/diptesh/PR-AAAI22-SDU-ST1-AE/data/english/legal/train.json', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized'] =data['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pos_dict'] = data['text'].apply(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>acronyms</th>\n",
       "      <th>longforms</th>\n",
       "      <th>ID</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12).;  Terms of reference A Correspondence Gro...</td>\n",
       "      <td>[[194, 199]]</td>\n",
       "      <td>[[164, 192]]</td>\n",
       "      <td>1</td>\n",
       "      <td>[12, ), ., ;,  ,  , Terms,  , of,  , reference...</td>\n",
       "      <td>{'12': 'NUM', ')': 'PUNCT', '.': 'PUNCT', ';':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The comprehensive list of currently identifie...</td>\n",
       "      <td>[[233, 238]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>[ , The,  , comprehensive,  , list,  , of,  , ...</td>\n",
       "      <td>{' ': 'SPACE', 'The': 'DET', 'comprehensive': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subregional activities for development Legisl...</td>\n",
       "      <td>[[142, 147]]</td>\n",
       "      <td>[[85, 140]]</td>\n",
       "      <td>3</td>\n",
       "      <td>[ , Subregional,  , activities,  , for,  , dev...</td>\n",
       "      <td>{' ': 'SPACE', 'Subregional': 'ADJ', 'activiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OIOS recommended that Secretariat programmes t...</td>\n",
       "      <td>[[239, 247], [142, 146], [0, 4]]</td>\n",
       "      <td>[[167, 237]]</td>\n",
       "      <td>4</td>\n",
       "      <td>[OIOS,  , recommended,  , that,  , Secretariat...</td>\n",
       "      <td>{'OIOS': 'PROPN', 'recommended': 'VERB', 'that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98. The Ministry of Education and Culture has...</td>\n",
       "      <td>[[82, 86]]</td>\n",
       "      <td>[[71, 80]]</td>\n",
       "      <td>5</td>\n",
       "      <td>[ , 98, .,  , The,  , Ministry,  , of,  , Educ...</td>\n",
       "      <td>{' ': 'SPACE', '98': 'NUM', '.': 'PUNCT', 'The...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  12).;  Terms of reference A Correspondence Gro...   \n",
       "1   The comprehensive list of currently identifie...   \n",
       "2   Subregional activities for development Legisl...   \n",
       "3  OIOS recommended that Secretariat programmes t...   \n",
       "4   98. The Ministry of Education and Culture has...   \n",
       "\n",
       "                           acronyms     longforms  ID  \\\n",
       "0                      [[194, 199]]  [[164, 192]]   1   \n",
       "1                      [[233, 238]]            []   2   \n",
       "2                      [[142, 147]]   [[85, 140]]   3   \n",
       "3  [[239, 247], [142, 146], [0, 4]]  [[167, 237]]   4   \n",
       "4                        [[82, 86]]    [[71, 80]]   5   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [12, ), ., ;,  ,  , Terms,  , of,  , reference...   \n",
       "1  [ , The,  , comprehensive,  , list,  , of,  , ...   \n",
       "2  [ , Subregional,  , activities,  , for,  , dev...   \n",
       "3  [OIOS,  , recommended,  , that,  , Secretariat...   \n",
       "4  [ , 98, .,  , The,  , Ministry,  , of,  , Educ...   \n",
       "\n",
       "                                            pos_dict  \n",
       "0  {'12': 'NUM', ')': 'PUNCT', '.': 'PUNCT', ';':...  \n",
       "1  {' ': 'SPACE', 'The': 'DET', 'comprehensive': ...  \n",
       "2  {' ': 'SPACE', 'Subregional': 'ADJ', 'activiti...  \n",
       "3  {'OIOS': 'PROPN', 'recommended': 'VERB', 'that...  \n",
       "4  {' ': 'SPACE', '98': 'NUM', '.': 'PUNCT', 'The...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the name of long-forms column for applying the function directly on the column\n",
    "data = data.rename(columns={\"long-forms\": \"longforms\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The function for annotating with BIO :\n",
    " 1. Long-forms are annotated as: B-LF, I-LF\n",
    " 2. Acronyms are annotated as: B-AC (all subwords are concatenated e.g. un-women are treated as one acronym)\n",
    " 3. Other is annotated as: B-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio(text,longforms,acronyms,tokens):\n",
    "    \n",
    "    acr_acc = ''\n",
    "    acr_start_flag = 0\n",
    "    char_index = 0\n",
    "    label_flag = 0\n",
    "    sent_labeled = []\n",
    "    for w in tokens:\n",
    "        label_flag = 0\n",
    "        if w in [' ', '(', ')'] and not(acr_start_flag):\n",
    "            char_index += 1\n",
    "            continue  \n",
    "        #check longforms\n",
    "        for indx in longforms:\n",
    "            if char_index == indx[0]:\n",
    "                sent_labeled.append((w,'B-LF'))\n",
    "                label_flag = 1\n",
    "                break\n",
    "            elif indx[0] < char_index < indx[1]:\n",
    "                sent_labeled.append((w,'I-LF'))\n",
    "                label_flag = 1\n",
    "                break\n",
    "        \n",
    "        # check acronym\n",
    "        for indx in acronyms:\n",
    "            \n",
    "            if acr_start_flag and char_index >= indx[1]:\n",
    "               \n",
    "                sent_labeled.append((acr_acc,'B-AC'))\n",
    "                acr_start_flag = 0\n",
    "                acr_acc = ''\n",
    "            if char_index == indx[0]:\n",
    "                \n",
    "                acr_acc += w\n",
    "                label_flag = 1\n",
    "                acr_start_flag = 1\n",
    "                break\n",
    "            elif indx[0] < char_index < indx[1]:\n",
    "                \n",
    "                acr_acc += w\n",
    "                \n",
    "                label_flag = 1\n",
    "                break\n",
    "            #  check O label\n",
    "        if label_flag == 0:\n",
    "            sent_labeled.append((w,'B-O'))\n",
    "        char_index += len(w)\n",
    "        \n",
    "    return sent_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function for annotating with BIO and POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_bio(text,longforms,acronyms,tokens, pos_dict):\n",
    "    \n",
    "    acr_acc = ''\n",
    "    acr_start_flag = 0\n",
    "    acr_acc_pos = 'PROPN'\n",
    "    char_index = 0\n",
    "    label_flag = 0\n",
    "    sent_labeled = []\n",
    "    \n",
    "    for w in tokens:\n",
    "        label_flag = 0\n",
    "        if w in [' ', '(', ')'] and not(acr_start_flag):\n",
    "            char_index += 1\n",
    "            continue  \n",
    "        #check longforms\n",
    "        for indx in longforms:\n",
    "            if char_index == indx[0]:\n",
    "                sent_labeled.append((w, pos_dict[w],'B-LF'))\n",
    "                label_flag = 1\n",
    "                break\n",
    "            elif indx[0] < char_index < indx[1]:\n",
    "                if(w not in pos_dict.keys()):\n",
    "                    pos_dict[w] = 'PUNCT'\n",
    "                sent_labeled.append((w, pos_dict[w],'I-LF'))\n",
    "                label_flag = 1\n",
    "                break\n",
    "        \n",
    "        # check acronym\n",
    "        for indx in acronyms:\n",
    "            \n",
    "            if acr_start_flag and char_index >= indx[1]:\n",
    "               \n",
    "                sent_labeled.append((acr_acc,acr_acc_pos,'B-AC'))\n",
    "                acr_start_flag = 0\n",
    "                acr_acc = ''\n",
    "            if char_index == indx[0]:\n",
    "                \n",
    "                acr_acc += w\n",
    "               \n",
    "                label_flag = 1\n",
    "                acr_start_flag = 1\n",
    "                break\n",
    "            elif indx[0] < char_index < indx[1]:\n",
    "                \n",
    "                acr_acc += w\n",
    "            \n",
    "                label_flag = 1\n",
    "                break\n",
    "            #  check O label\n",
    "        if label_flag == 0:\n",
    "            if(w not in pos_dict.keys()):\n",
    "                pos_dict[w] = 'PUNCT'\n",
    "                print(w)\n",
    "            sent_labeled.append((w,pos_dict[w],'B-O'))\n",
    "        char_index += len(w)\n",
    "        \n",
    "    return sent_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3564, 6)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the function to the dataframe directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_eng_train_legal = data.apply(lambda x: bio(x.text, x.longforms,x.acronyms,x.tokenized), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "pos_bio_eng_train_legal = data.apply(lambda x: pos_bio(x.text, x.longforms,x.acronyms,x.tokenized, x.pos_dict), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the POS, BIO list into a txt file with each token, POS, and BIO annotation on one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(12, B-O), (., B-O), (;, B-O), (Terms, B-O), ...\n",
       "1       [(The, B-O), (comprehensive, B-O), (list, B-O)...\n",
       "2       [(Subregional, B-O), (activities, B-O), (for, ...\n",
       "3       [(OIOS, B-AC), ( , B-O), (recommended, B-O), (...\n",
       "4       [(98, B-O), (., B-O), (The, B-O), (Ministry, B...\n",
       "                              ...                        \n",
       "3559    [(The, B-O), (Twenty, B-O), (-, B-O), (fourth,...\n",
       "3560    [(UNCITRAL, B-AC), ( , B-O), (Model, B-O), (La...\n",
       "3561    [(62, B-O), (., B-O), (Some, B-O), (of, B-O), ...\n",
       "3562    [(It, B-O), (stressed, B-O), (the, B-O), (impo...\n",
       "3563    [(44, B-O), (., B-O), (At, B-O), (the, B-O), (...\n",
       "Length: 3564, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_eng_train_legal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(12, NUM, B-O), (., PUNCT, B-O), (;, PUNCT, B...\n",
       "1       [(The, DET, B-O), (comprehensive, ADJ, B-O), (...\n",
       "2       [(Subregional, ADJ, B-O), (activities, NOUN, B...\n",
       "3       [(OIOS, PROPN, B-AC), ( , SPACE, B-O), (recomm...\n",
       "4       [(98, NUM, B-O), (., PUNCT, B-O), (The, DET, B...\n",
       "                              ...                        \n",
       "3559    [(The, DET, B-O), (Twenty, NUM, B-O), (-, PUNC...\n",
       "3560    [(UNCITRAL, PROPN, B-AC), ( , PUNCT, B-O), (Mo...\n",
       "3561    [(62, NUM, B-O), (., PUNCT, B-O), (Some, DET, ...\n",
       "3562    [(It, PRON, B-O), (stressed, VERB, B-O), (the,...\n",
       "3563    [(44, NUM, B-O), (., PUNCT, B-O), (At, ADP, B-...\n",
       "Length: 3564, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_bio_eng_train_legal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12', 'B-O'),\n",
       " ('.', 'B-O'),\n",
       " (';', 'B-O'),\n",
       " ('Terms', 'B-O'),\n",
       " ('of', 'B-O'),\n",
       " ('reference', 'B-O'),\n",
       " ('A', 'B-O'),\n",
       " ('Correspondence', 'B-O'),\n",
       " ('Group', 'B-O'),\n",
       " ('coordinated', 'B-O'),\n",
       " ('by', 'B-O'),\n",
       " ('the', 'B-O'),\n",
       " ('expert', 'B-O'),\n",
       " ('of', 'B-O'),\n",
       " ('the', 'B-O'),\n",
       " ('United', 'B-O'),\n",
       " ('Kingdom', 'B-O'),\n",
       " (',', 'B-O'),\n",
       " ('and', 'B-O'),\n",
       " ('including', 'B-O'),\n",
       " ('representatives', 'B-O'),\n",
       " ('of', 'B-O'),\n",
       " ('affected', 'B-O'),\n",
       " ('industries', 'B-O'),\n",
       " ('and', 'B-O'),\n",
       " ('users', 'B-O'),\n",
       " ('of', 'B-O'),\n",
       " ('intermediate', 'B-LF'),\n",
       " ('bulk', 'I-LF'),\n",
       " ('containers', 'I-LF'),\n",
       " (\"IBC's\", 'B-AC'),\n",
       " (')', 'B-O'),\n",
       " (',', 'B-O'),\n",
       " ('shall', 'B-O'),\n",
       " ('examine', 'B-O'),\n",
       " ('current', 'B-O'),\n",
       " ('practices', 'B-O'),\n",
       " ('of', 'B-O'),\n",
       " ('UN', 'B-O'),\n",
       " ('composite', 'B-O'),\n",
       " ('IBC', 'B-O'),\n",
       " ('re', 'B-O'),\n",
       " ('-', 'B-O'),\n",
       " ('bottling', 'B-O'),\n",
       " ('and', 'B-O'),\n",
       " ('cross', 'B-O'),\n",
       " ('bottling', 'B-O'),\n",
       " ('in', 'B-O'),\n",
       " ('several', 'B-O'),\n",
       " ('countries', 'B-O'),\n",
       " ('.', 'B-O')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_eng_train_legal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bio_eng_leg_train.txt', 'w') as outfile:\n",
    "    for ls in bio_eng_train_legal:\n",
    "        for tup in ls:\n",
    "            line = \" \".join(map(str, tup))\n",
    "        \n",
    "            outfile.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pos_bio_eng_leg_train.txt', 'w') as outfile:\n",
    "    for ls in pos_bio_eng_train_legal:\n",
    "        for tup in ls:\n",
    "            line = \" \".join(map(str, tup))\n",
    "        \n",
    "            outfile.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
